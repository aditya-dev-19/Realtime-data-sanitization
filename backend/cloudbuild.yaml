steps:
# STEP 1: Build the Docker image
# This step no longer needs to worry about LFS files.
# It builds the image using the Dockerfile in the 'backend' directory.
- name: 'gcr.io/cloud-builders/docker'
  dir: 'backend'
  args: ['build', '-t', 'gcr.io/$PROJECT_ID/realtime-data-sanitization:$COMMIT_SHA', '.']

# STEP 2: Push the image to Google Container Registry
- name: 'gcr.io/cloud-builders/docker'
  args: ['push', 'gcr.io/$PROJECT_ID/realtime-data-sanitization:$COMMIT_SHA']

# STEP 3: Deploy the new image to Cloud Run
- name: 'gcr.io/google.com/cloudsdktool/cloud-sdk'
  entrypoint: gcloud
  args:
    - 'run'
    - 'deploy'
    - 'cybersecurity-api-service'   # Your Cloud Run service name
    - '--image'
    - 'gcr.io/$PROJECT_ID/realtime-data-sanitization:$COMMIT_SHA'
    - '--region'
    - 'us-central1'                 # Your service region
    - '--platform'
    - 'managed'
    - '--allow-unauthenticated'
    # [MODIFIED] Add a longer startup timeout
    - '--startup-cpu-boost'
    - '--timeout=15m' # Increase overall request timeout if needed
    - '--cpu-boost'
    # Important: Ensure your Cloud Run service has permissions to access the GCS bucket.
    # This is typically done by assigning the 'Storage Object Viewer' role
    # to the service account used by Cloud Run.

images:
  - 'gcr.io/$PROJECT_ID/realtime-data-sanitization:$COMMIT_SHA'

options:
  logging: CLOUD_LOGGING_ONLY