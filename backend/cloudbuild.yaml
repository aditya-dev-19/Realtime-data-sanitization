steps:
# STEP 1: Build the Docker image
# This step no longer needs to worry about LFS files.
# It builds the image using the Dockerfile in the 'backend' directory.
- name: 'gcr.io/cloud-builders/docker'
  dir: 'backend'
  args: ['build', '-t', 'gcr.io/$PROJECT_ID/realtime-data-sanitization:$COMMIT_SHA', '.']

# STEP 2: Push the image to Google Container Registry
- name: 'gcr.io/cloud-builders/docker'
  args: ['push', 'gcr.io/$PROJECT_ID/realtime-data-sanitization:$COMMIT_SHA']

# STEP 3: Deploy the new image to Cloud Run
- name: 'gcr.io/google.com/cloudsdktool/cloud-sdk'
  entrypoint: gcloud
  args:
    - 'run'
    - 'deploy'
    - 'cybersecurity-api-service'   # Your Cloud Run service name
    - '--image'
    - 'gcr.io/$PROJECT_ID/realtime-data-sanitization:$COMMIT_SHA'
    - '--region'
    - 'us-central1'                 # Your service region
    - '--platform'
    - 'managed'
    - '--allow-unauthenticated'
    # [CORRECTED] Use valid flags for resources and timeout
    - '--memory=4Gi'                # Allocate more memory for loading models
    - '--timeout=900'               # Increase timeout to 15 minutes (900 seconds)
    - '--cpu-boost'                 # Enable CPU boost for faster startup
    # Important: Ensure your Cloud Run service has permissions to access the GCS bucket.
    # This is typically done by assigning the 'Storage Object Viewer' role
    # to the service account used by Cloud Run.
    - 'GOOGLE_CLOUD_PROJECT=$PROJECT_ID,SECRET_KEY=$$SECRET_KEY'  # ðŸ‘ˆ ADD THIS

substitutions:
  _SECRET_KEY: 'ec026aaa81c7762d33ad142dd8ca4801710747549d307b1a642ed2004ccf42c6'  # ðŸ‘ˆ ADD THIS

secretEnv: ['SECRET_KEY']  # ðŸ‘ˆ ADD THIS

availableSecrets:
  secretManager:
  - versionName: projects/$PROJECT_ID/secrets/SECRET_KEY/versions/latest
    env: 'SECRET_KEY'

images:
  - 'gcr.io/$PROJECT_ID/realtime-data-sanitization:$COMMIT_SHA'

options:
  logging: CLOUD_LOGGING_ONLY